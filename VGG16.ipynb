{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "VGG ( Visual Geometry Group ) is a widely used type of neural network architecture a CNN, known for its unifrom design.\n",
        "The numbers in VGG16 or VGG19 refer to the depth of neural network."
      ],
      "metadata": {
        "id": "06J1J8LxY3wN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heEThTKHYzNL"
      },
      "outputs": [],
      "source": [
        "# there are 6 block of network\n",
        "# block 1 : 2 Conv layer + ReLU and a Pooling\n",
        "# block 2 : 2 Conv Layer + ReLU and a pooling\n",
        "# block 3 : 3 Conv Layer + ReLU and a Pooling\n",
        "# block 4 : 3 Conv Layer + ReLU and a Pooling\n",
        "# block 5 : 3 Conv Layer + ReLU and a Pooling\n",
        "# block 6 : 3 FC layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data.sampler import SubsetRandomSampler # to ranomly sample data\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "dFRk6HjJb4wS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Device Config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF3zYsuic-lF",
        "outputId": "0c7569a8-69d2-43d3-dc4b-64245258e87c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT65MhUokpM8",
        "outputId": "89d99f99-5586-49cf-9938-0ef95f0f36bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_input_dataset_dir =  \"/content/drive/My Drive/input_dataset\""
      ],
      "metadata": {
        "id": "8JJ5JanVkuUj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loader\n",
        "def data_loader( data_dir, batch_size , random_seed = 42, shuffle = True, valid_size=0.1 , test = False):\n",
        "\n",
        "  # Normalization\n",
        "  # define transforms\n",
        "  # make the size of images uniform\n",
        "  transform = transforms.Compose([\n",
        "      transforms.Resize((227,227)),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(\n",
        "      mean = [ 0.4914, 0.4822, 0.4465],\n",
        "      std = [ 0.2023, 0.1994, 0.2010])\n",
        "    ])\n",
        "\n",
        "  if test:\n",
        "    dataset = datasets.CIFAR100( root = data_dir, train = False, download = True, transform = transform)\n",
        "    data_loader = torch.utils.data.DataLoader( dataset = dataset, batch_size = batch_size, shuffle = shuffle)\n",
        "    return data_loader\n",
        "\n",
        "  train_dataset = datasets.CIFAR100( root = data_dir, download = True , train = True, transform=transform)\n",
        "  val_dataset = datasets.CIFAR100( root = data_dir, download = True , train = True, transform=transform)\n",
        "\n",
        "  num_train = len(train_dataset)\n",
        "  indices = list( range(num_train))\n",
        "  split = int(np.floor(valid_size*num_train))\n",
        "\n",
        "  if shuffle:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices) # for shuffleing the dataset\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    val_data_loader = torch.utils.data.DataLoader( dataset = val_dataset, batch_size = batch_size, sampler = train_sampler )\n",
        "    train_data_loader = torch.utils.data.DataLoader( dataset = train_dataset, batch_size = batch_size, sampler = train_sampler )\n",
        "\n",
        "    return (train_data_loader, val_data_loader)\n"
      ],
      "metadata": {
        "id": "DnP9n3GpdJzL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader ,valid_loader = data_loader( root_input_dataset_dir, batch_size = 64 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBsUn9YDj-yz",
        "outputId": "3f0df6cf-6229-4311-8d41-7c378fd7834d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8wH5sx3k7vL",
        "outputId": "02250ed4-f8f3-43f1-d2dd-4ec0b32df438"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "704"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = data_loader( root_input_dataset_dir, batch_size = 64, test = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUSGu5MDlJwU",
        "outputId": "0c7f749b-3fc4-452e-e7a5-e06871347d70"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG16(nn.Module):\n",
        "\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(VGG16, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Conv2d( 3, 64, kernel_size = 3 , stride = 1, padding =1 ),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(64, 64, kernel_size = 3 ,stride = 1, padding =1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size =2, stride =2)\n",
        "    )\n",
        "\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Conv2d(64, 128, kernel_size = 3 ,stride = 1, padding =1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.layer4 = nn.Sequential(\n",
        "        nn.Conv2d(128, 128, kernel_size = 3 ,stride = 1, padding =1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size =2, stride =2)\n",
        "    )\n",
        "\n",
        "    self.layer5 = nn.Sequential(\n",
        "        nn.Conv2d(128, 256, kernel_size = 3 ,stride = 1, padding =1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.layer6 = nn.Sequential(\n",
        "        nn.Conv2d(256, 256, kernel_size = 3 ,stride = 1, padding =1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.layer7 = nn.Sequential(\n",
        "        nn.Conv2d(256, 256, kernel_size = 3 ,stride = 1, padding =1),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size =2, stride =2)\n",
        "    )\n",
        "\n",
        "    self.layer8 = nn.Sequential(\n",
        "        nn.Conv2d(256, 512, kernel_size = 3 ,stride = 1, padding =1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.layer9 = nn.Sequential(\n",
        "        nn.Conv2d(512, 512, kernel_size = 3 ,stride = 1, padding =1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.layer10 = nn.Sequential(\n",
        "        nn.Conv2d(512, 512, kernel_size = 3 ,stride = 1, padding =1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size =2, stride =2)\n",
        "    )\n",
        "\n",
        "    self.layer11 = nn.Sequential(\n",
        "        nn.Conv2d(512, 512, kernel_size = 3 ,stride = 1, padding =1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.layer12 = nn.Sequential(\n",
        "        nn.Conv2d(512, 512, kernel_size = 3 ,stride = 1, padding =1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.layer13 = nn.Sequential(\n",
        "        nn.Conv2d(512, 512, kernel_size = 3 ,stride = 1, padding =1),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size =2, stride =2)\n",
        "    )\n",
        "\n",
        "    self.fc1 = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(7*7*512, 4096),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.fc2 = nn.Sequential(\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.fc3 = nn.Sequential(\n",
        "        nn.Linear(4096, num_classes)\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    out = self.layer5(out)\n",
        "    out = self.layer6(out)\n",
        "    out = self.layer7(out)\n",
        "    out = self.layer8(out)\n",
        "    out = self.layer9(out)\n",
        "    out = self.layer10(out)\n",
        "    out = self.layer11(out)\n",
        "    out = self.layer12(out)\n",
        "    out = self.layer13(out)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc1(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.fc3(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "MQnu2Z07lVG0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining hyperparameter\n",
        "num_classes= 100\n",
        "num_epochs = 20\n",
        "batch_size = 16\n",
        "learning_rate =0.001\n"
      ],
      "metadata": {
        "id": "OsG73VjTp63S"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16(num_classes).to(device)"
      ],
      "metadata": {
        "id": "ejm4Mz3Lqbs2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 227,227))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5onvhvKqeRF",
        "outputId": "1233b697-8975-4e02-c082-ac903cd2450c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 227, 227]           1,792\n",
            "       BatchNorm2d-2         [-1, 64, 227, 227]             128\n",
            "              ReLU-3         [-1, 64, 227, 227]               0\n",
            "            Conv2d-4         [-1, 64, 227, 227]          36,928\n",
            "       BatchNorm2d-5         [-1, 64, 227, 227]             128\n",
            "              ReLU-6         [-1, 64, 227, 227]               0\n",
            "         MaxPool2d-7         [-1, 64, 113, 113]               0\n",
            "            Conv2d-8        [-1, 128, 113, 113]          73,856\n",
            "       BatchNorm2d-9        [-1, 128, 113, 113]             256\n",
            "             ReLU-10        [-1, 128, 113, 113]               0\n",
            "           Conv2d-11        [-1, 128, 113, 113]         147,584\n",
            "      BatchNorm2d-12        [-1, 128, 113, 113]             256\n",
            "             ReLU-13        [-1, 128, 113, 113]               0\n",
            "        MaxPool2d-14          [-1, 128, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         295,168\n",
            "      BatchNorm2d-16          [-1, 256, 56, 56]             512\n",
            "             ReLU-17          [-1, 256, 56, 56]               0\n",
            "           Conv2d-18          [-1, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-19          [-1, 256, 56, 56]             512\n",
            "             ReLU-20          [-1, 256, 56, 56]               0\n",
            "           Conv2d-21          [-1, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-22          [-1, 256, 56, 56]             512\n",
            "             ReLU-23          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-24          [-1, 256, 28, 28]               0\n",
            "           Conv2d-25          [-1, 512, 28, 28]       1,180,160\n",
            "      BatchNorm2d-26          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-27          [-1, 512, 28, 28]               0\n",
            "           Conv2d-28          [-1, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-29          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-30          [-1, 512, 28, 28]               0\n",
            "           Conv2d-31          [-1, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-32          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-33          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-34          [-1, 512, 14, 14]               0\n",
            "           Conv2d-35          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-36          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-37          [-1, 512, 14, 14]               0\n",
            "           Conv2d-38          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-39          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-40          [-1, 512, 14, 14]               0\n",
            "           Conv2d-41          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-42          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-43          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-44            [-1, 512, 7, 7]               0\n",
            "          Dropout-45                [-1, 25088]               0\n",
            "           Linear-46                 [-1, 4096]     102,764,544\n",
            "             ReLU-47                 [-1, 4096]               0\n",
            "          Dropout-48                 [-1, 4096]               0\n",
            "           Linear-49                 [-1, 4096]      16,781,312\n",
            "             ReLU-50                 [-1, 4096]               0\n",
            "           Linear-51                  [-1, 100]         409,700\n",
            "================================================================\n",
            "Total params: 134,678,692\n",
            "Trainable params: 134,678,692\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.59\n",
            "Forward/backward pass size (MB): 327.49\n",
            "Params size (MB): 513.76\n",
            "Estimated Total Size (MB): 841.84\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD( model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "7U92Mp98qxII"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)"
      ],
      "metadata": {
        "id": "Vl2c2aHmrLk3"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "\n",
        "    predictions = model(images)\n",
        "    loss = criterion(predictions)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "\n",
        "    correct = 0\n",
        "    total =0\n",
        "\n",
        "    for images, labels in valid_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      predictions = model(images)\n",
        "      _, predicted = torch.max(predictions.data.item(), 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      del images, labels, predictions\n",
        "\n",
        "    print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))\n"
      ],
      "metadata": {
        "id": "GqyrWEDTrN3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for test dataset\n",
        "with torch.no_grad():\n",
        "\n",
        "    correct = 0\n",
        "    total =0\n",
        "\n",
        "    for images, labels in test_loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      predictions = model(images)\n",
        "      _, predicted = torch.max(predictions.data.item(), 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      del images, labels, predictions\n",
        "\n",
        "    print('Accuracy of the network on the {} validation images: {} %'.format(5000, 100 * correct / total))\n"
      ],
      "metadata": {
        "id": "JtriscyhshSf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}